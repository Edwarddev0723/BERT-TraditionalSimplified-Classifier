{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa7cf1cb",
   "metadata": {},
   "source": [
    "# Fine-tune: BERT Traditional vs Taiwan (English)\n",
    "This notebook fine-tunes the packaged classifier on your dataset using config files in `configs/`. It demonstrates:\n",
    "- Quick environment and import checks\n",
    "- Loading configs and paths\n",
    "- Training via a subprocess call to the CLI entrypoint\n",
    "- Evaluation via the CLI\n",
    "Notes:\n",
    "- Requires the project to be installed/available in the current environment.\n",
    "- Cells are designed to run end-to-end with cleared outputs by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e669a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment & imports\n",
    "import sys, platform, torch\n",
    "print({\"python\": sys.version.split()[0], \"platform\": platform.platform(), \"torch\": torch.__version__})\n",
    "try:\n",
    "    import bert_ts_classifier as pkg\n",
    "    print({\"package\": pkg.__name__})\n",
    "except Exception as e:\n",
    "    print(\"Package import failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths\n",
    "from pathlib import Path\n",
    "from bert_ts_classifier.utils.io import load_yaml\n",
    "DATA_CFG = Path(\"configs/data.yaml\").resolve()\n",
    "MODEL_CFG = Path(\"configs/model.yaml\").resolve()\n",
    "TRAIN_CFG = Path(\"configs/train.yaml\").resolve()\n",
    "EVAL_CFG = Path(\"configs/eval.yaml\").resolve()\n",
    "print({\"data\": str(DATA_CFG), \"model\": str(MODEL_CFG), \"train\": str(TRAIN_CFG), \"eval\": str(EVAL_CFG)})\n",
    "cfg_preview = {\"data\": load_yaml(DATA_CFG), \"model\": load_yaml(MODEL_CFG), \"train\": load_yaml(TRAIN_CFG), \"eval\": load_yaml(EVAL_CFG)}\n",
    "print(\"Loaded configs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6464646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train via CLI (subprocess)\n",
    "import subprocess, shlex\n",
    "cmd = \"python -m bert_ts_classifier.training.train --config configs/train.yaml\"\n",
    "# Example override: reduce epochs for quick runs\n",
    "# cmd = cmd + \" train.max_epochs=1 data.batch_size=8\"\n",
    "print(\"Running:\", cmd)\n",
    "res = subprocess.run(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "print(res.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81333f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate via CLI (subprocess)\n",
    "import subprocess, shlex\n",
    "cmd = \"python -m bert_ts_classifier.evaluation.eval --config configs/eval.yaml\"\n",
    "print(\"Running:\", cmd)\n",
    "res = subprocess.run(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "print(res.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb654f",
   "metadata": {},
   "source": [
    "# Notes & tips\n",
    "- To speed up quick experiments, lower `train.max_epochs` and `data.batch_size` via overrides.\n",
    "- For GPU/MPS, the scripts auto-select available device.\n",
    "- See `PR_DRAFT.md` for command-line quickstart and CI details."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
